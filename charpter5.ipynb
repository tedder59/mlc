{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6094d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import tvm\n",
    "\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import relax as R\n",
    "from tvm.script import tir as T\n",
    "from tvm import relax\n",
    "from torch import fx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e37437e",
   "metadata": {},
   "source": [
    "Tensor expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8667ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">func</span>(\n",
       "    A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "):\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "            v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "            matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tvm import te\n",
    "\n",
    "A = te.placeholder((128, 128), name=\"A\", dtype=\"float32\")\n",
    "B = te.placeholder((128, 128), name=\"B\", dtype=\"float32\")\n",
    "\n",
    "def te_matmul(A: te.Tensor, B: te.Tensor) -> te.Tensor:\n",
    "    assert A.shape[1] == B.shape[0]\n",
    "    n = A.shape[0]\n",
    "    m = B.shape[1]\n",
    "    k = te.reduce_axis((0, A.shape[1]), name=\"k\")\n",
    "    return te.compute((n, m), lambda i, j: te.sum(A[i, k] * B[k, j], axis=k), name=\"matmul\")\n",
    "\n",
    "C = te_matmul(A, B)\n",
    "te.create_prim_func([A, B, C]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69664a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">func</span>(placeholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[<span style=\"color: #008000\">10</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[<span style=\"color: #008000\">10</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>serial(<span style=\"color: #008000\">10</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "            v_i0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">10</span>, i0)\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(placeholder[v_i0])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0])\n",
       "            relu[v_i0] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(placeholder[v_i0], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X1 = te.placeholder((10,), dtype=\"float32\")\n",
    "\n",
    "def te_relu(A: te.Tensor) -> te.Tensor:\n",
    "    return te.compute(A.shape, lambda *i: te.max(A(*i), 0), name='relu')\n",
    "\n",
    "Y1 = te_relu(X1)\n",
    "te.create_prim_func([X1, Y1]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f05d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">func</span>(\n",
       "    placeholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]\n",
       "):\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "            v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(placeholder[v_i0, v_i1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
       "            relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(placeholder[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X2 = te.placeholder((10, 20), dtype=\"float32\")\n",
    "Y2 = te_relu(X2)\n",
    "te.create_prim_func([X2, Y2]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb4b856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">func</span>(\n",
       "    A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "):\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    matmul <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer([<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "            v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "            matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "            v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(matmul[v_i0, v_i1])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
       "            relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(matmul[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = te_relu(C)\n",
    "te.create_prim_func([A, B, D]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5ecb5",
   "metadata": {},
   "source": [
    "BlockBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ea6263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_matmul</span>(\n",
       "        rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_k], rxplaceholder_1[v_k, v_j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> (\n",
       "                    matmul[v_i, v_j]\n",
       "                    <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_k, v_j]\n",
       "                )\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_relu</span>(\n",
       "        rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
       "                relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        A: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "        B: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "    ) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                te_matmul, (A, B), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            )\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                te_relu, (lv,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            )\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = relax.Var(\"A\", relax.TensorStructInfo((128, 128), \"float32\"))\n",
    "B = relax.Var(\"B\", relax.TensorStructInfo((128, 128), \"float32\"))\n",
    "\n",
    "bb = relax.BlockBuilder()\n",
    "with bb.function(\"main\"):\n",
    "    with bb.dataflow():\n",
    "        C = bb.emit_te(te_matmul, A, B)\n",
    "        D = bb.emit_te(te_relu, C)\n",
    "        R = bb.emit_output(D)\n",
    "    bb.emit_func_output(R, params=[A, B])\n",
    "    \n",
    "MyModule = bb.get()\n",
    "MyModule.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f4018",
   "metadata": {},
   "source": [
    "torch.fx call_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35455d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                     args         kwargs\n",
      "-------------  ------  ---------------------------------------------------------  -----------  --------\n",
      "placeholder    x       x                                                          ()           {}\n",
      "get_attr       weight  weight                                                     ()           {}\n",
      "call_function  matmul  <built-in method matmul of type object at 0x7f822ab36e00>  (x, weight)  {}\n",
      "call_function  relu    <built-in method relu of type object at 0x7f822ab36e00>    (matmul,)    {}\n",
      "output         output  output                                                     (relu,)      {}\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(128, 128))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(x, self.weight)\n",
    "        x = torch.relu(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "model = MyModel()\n",
    "fx_module = fx.symbolic_trace(model)\n",
    "fx_module.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3378058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_param(param: nn.Parameter):\n",
    "    ndim = len(param.data.shape)\n",
    "    return relax.const(param.data.cpu().numpy(), relax.DynTensorType(ndim, \"float32\"))\n",
    "\n",
    "def fetch_attr(fx_mod, target: str):\n",
    "    target_atoms = target.split('.')\n",
    "    attr_iter = fx_mod\n",
    "    for i, atom in enumerate(target_atoms):\n",
    "        if not hasattr(attr_iter, atom):\n",
    "            raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "        attr_iter = getattr(attr_iter, atom)\n",
    "    return attr_iter\n",
    "\n",
    "def from_fx(fx_mod, input_shapes, call_function_map, call_module_map):\n",
    "    input_index = 0\n",
    "    node_map = {}\n",
    "    named_modules = dict(fx_mod.named_modules())\n",
    "    bb = relax.BlockBuilder()\n",
    "    \n",
    "    fn_inputs = []\n",
    "    fn_output = None\n",
    "    with bb.function(\"main\"):\n",
    "        with bb.dataflow():\n",
    "            for node in fx_mod.graph.nodes:\n",
    "                if node.op == \"placeholder\":\n",
    "                    shape = input_shapes[input_index]\n",
    "                    input_index += 1\n",
    "                    input_var = relax.Var(node.target, relax.TensorStructInfo(shape, \"float32\"))\n",
    "                    fn_inputs.append(input_var)\n",
    "                    node_map[node] = input_var\n",
    "                elif node.op == \"get_attr\":\n",
    "                    node_map[node] = map_param(fetch_attr(fx_mod, node.target))\n",
    "                elif node.op == \"call_function\":\n",
    "                    node_map[node] = call_function_map[node.target](bb, node_map, node)\n",
    "                elif node.op == \"call_module\":\n",
    "                    named_module = named_modules[node.target]\n",
    "                    node_map[node] = call_module_map[type(named_module)](bb, node_map, node, named_module)\n",
    "                elif node.op == \"output\":\n",
    "                    output = node_map[node.args[0]]\n",
    "                    assert fn_output is None\n",
    "                    fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(output, fn_inputs)\n",
    "        \n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "171d64ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_matmul</span>(\n",
       "        rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
       "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_k], rxplaceholder_1[v_k, v_j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> (\n",
       "                    matmul[v_i, v_j]\n",
       "                    <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_k, v_j]\n",
       "                )\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_relu</span>(\n",
       "        rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
       "                relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "    ) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                te_matmul,\n",
       "                (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>]),\n",
       "                out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "            )\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                te_relu, (lv,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            )\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> lv1\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_matmul(bb, node_map, node: fx.Node):\n",
    "    A = node_map[node.args[0]]\n",
    "    B = node_map[node.args[1]]\n",
    "    return bb.emit_te(te_matmul, A, B)\n",
    "\n",
    "def map_relu(bb, node_map, node: fx.Node):\n",
    "    A = node_map[node.args[0]]\n",
    "    return bb.emit_te(te_relu, A)\n",
    "\n",
    "MyModule = from_fx(fx_module, input_shapes=[(1, 128)],\n",
    "                   call_function_map={\n",
    "                       torch.matmul: map_matmul,\n",
    "                       torch.relu: map_relu\n",
    "                   }, call_module_map={})\n",
    "\n",
    "MyModule.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cf461",
   "metadata": {},
   "source": [
    "torch.fx call_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f16baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name     target    args        kwargs\n",
      "-----------  -------  --------  ----------  --------\n",
      "placeholder  x        x         ()          {}\n",
      "call_module  linear0  linear0   (x,)        {}\n",
      "call_module  relu     relu      (linear0,)  {}\n",
      "call_module  linear1  linear1   (relu,)     {}\n",
      "output       output   output    (linear1,)  {}\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear0 = nn.Linear(784, 128, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(128, 10, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "    \n",
    "mlp_model = MLP()\n",
    "mlp_params = pkl.load(open(\"fasionmnist_mlp_params.pkl\", 'rb'))\n",
    "mlp_model.linear0.weight.data = torch.from_numpy(mlp_params['w0'])\n",
    "mlp_model.linear0.bias.data = torch.from_numpy(mlp_params['b0'])\n",
    "mlp_model.linear1.weight.data = torch.from_numpy(mlp_params['w1'])\n",
    "mlp_model.linear1.bias.data = torch.from_numpy(mlp_params['b1'])\n",
    "\n",
    "fx_module = fx.symbolic_trace(mlp_model)\n",
    "fx_module.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60d38f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "    ) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                dense,\n",
       "                (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>]),\n",
       "                out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "            )\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                add,\n",
       "                (lv, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>]),\n",
       "                out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "            )\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                te_relu, (lv1,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            )\n",
       "            lv3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                dense1,\n",
       "                (lv2, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>]),\n",
       "                out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "            )\n",
       "            lv4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(\n",
       "                add1,\n",
       "                (lv3, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>]),\n",
       "                out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "            )\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv4\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> lv4\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add</span>(\n",
       "        rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_ax0, v_ax1], rxplaceholder_1[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
       "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> (\n",
       "                    rxplaceholder[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_1[v_ax1]\n",
       "                )\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">dense1</span>(\n",
       "        rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        T_matmul_NT: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT&quot;</span>):\n",
       "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_k], rxplaceholder_1[v_j, v_k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[v_i, v_j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> (\n",
       "                    T_matmul_NT[v_i, v_j]\n",
       "                    <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_j, v_k]\n",
       "                )\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">dense</span>(\n",
       "        rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        T_matmul_NT: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT&quot;</span>):\n",
       "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i, v_k], rxplaceholder_1[v_j, v_k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[v_i, v_j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> (\n",
       "                    T_matmul_NT[v_i, v_j]\n",
       "                    <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[v_j, v_k]\n",
       "                )\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_relu</span>(\n",
       "        rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
       "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_i0, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
       "                relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add1</span>(\n",
       "        rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "        T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>],\n",
       "    ):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[v_ax0, v_ax1], rxplaceholder_1[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
       "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> (\n",
       "                    rxplaceholder[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_1[v_ax1]\n",
       "                )\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tvm import topi\n",
    "\n",
    "def map_nn_linear(bb, node_map, node, nn_mod):\n",
    "    x = node_map[node.args[0]]\n",
    "    w = map_param(nn_mod.weight)\n",
    "    if nn_mod.bias is not None:\n",
    "        b = map_param(nn_mod.bias)\n",
    "    y = bb.emit_te(topi.nn.dense, x, w)\n",
    "    return bb.emit_te(topi.add, y, b)\n",
    "\n",
    "def map_nn_relu(bb, node_map, node, nn_mod):\n",
    "    return map_relu(bb, node_map, node)\n",
    "\n",
    "MLPModule = from_fx(fx_module, input_shapes=[(1, 784)],\n",
    "                    call_function_map={},\n",
    "                    call_module_map={\n",
    "                        torch.nn.Linear: map_nn_linear,\n",
    "                        torch.nn.ReLU: map_nn_relu\n",
    "                    })\n",
    "MLPModule.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accd5ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  Coat\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(root=\"data\", train=False, transform=torchvision.transforms.ToTensor())\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "img, lbl = next(iter(test_dataloader))\n",
    "img = img.reshape(1, 28, 28).numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "print(\"Class: \", class_names[lbl[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16c30178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Pred:  Coat\n"
     ]
    }
   ],
   "source": [
    "torch_res = mlp_model(torch.from_numpy(img.reshape(1, 784)))\n",
    "pred = np.argmax(torch_res.detach().numpy(), axis=1)\n",
    "print(\"Torch Pred: \", class_names[pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43226a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModule pred:  Coat\n"
     ]
    }
   ],
   "source": [
    "ex = relax.vm.build(MLPModule, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MLPModule pred: \", class_names[pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea911c6",
   "metadata": {},
   "source": [
    "high level relax.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f8f19d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "    ) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(\n",
       "                x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;&quot;</span>\n",
       "            )\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(\n",
       "                lv, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>]\n",
       "            )\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(lv1)\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(\n",
       "                lv2, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;&quot;</span>\n",
       "            )\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(\n",
       "                lv3, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>]\n",
       "            )\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv4\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> lv4\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_nn_relu_op(bb, node_map, node, nn_mod):\n",
    "    A = node_map[node.args[0]]\n",
    "    return bb.emit(relax.op.nn.relu(A))\n",
    "\n",
    "def map_nn_linear_op(bb, node_map, node, nn_mod):\n",
    "    x = node_map[node.args[0]]\n",
    "    w = map_param(nn_mod.weight.T)\n",
    "    if nn_mod.bias is not None:\n",
    "        b = map_param(nn_mod.bias)\n",
    "    y = bb.emit(relax.op.matmul(x, w))\n",
    "    return bb.emit(relax.op.add(y, b))\n",
    "\n",
    "MLPModuleHighLevel = from_fx(fx_module,\n",
    "                             input_shapes=[(1, 784)],\n",
    "                             call_function_map={},\n",
    "                             call_module_map={\n",
    "                                 torch.nn.Linear: map_nn_linear_op,\n",
    "                                 torch.nn.ReLU: map_nn_relu_op\n",
    "                             })\n",
    "\n",
    "MLPModuleHighLevel.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea60b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
